{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7104256,"sourceType":"datasetVersion","datasetId":4095523}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q bitsandbytes datasets accelerate loralib\n!pip install -q git+https://github.com/huggingface/peft.git git+https://github.com/huggingface/transformers.git\n!pip install -q scipy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-02T09:14:29.045309Z","iopub.execute_input":"2023-12-02T09:14:29.045897Z","iopub.status.idle":"2023-12-02T09:16:10.131187Z","shell.execute_reply.started":"2023-12-02T09:14:29.045868Z","shell.execute_reply":"2023-12-02T09:16:10.129921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport bitsandbytes as bnb\nfrom transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:16:10.133623Z","iopub.execute_input":"2023-12-02T09:16:10.134007Z","iopub.status.idle":"2023-12-02T09:16:19.093702Z","shell.execute_reply.started":"2023-12-02T09:16:10.133972Z","shell.execute_reply":"2023-12-02T09:16:19.092599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom peft import PeftModel, PeftConfig\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"ivr_model_llma_final\"\n\npeft_model_id = \"/kaggle/input/ivr-final-model-bak/ivr_model_llma_final\"\nconfig = PeftConfig.from_pretrained(peft_model_id)\nmodel = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, return_dict=True, load_in_8bit=True, device_map='auto')\ntokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n\n# Load the Lora model\nmodel = PeftModel.from_pretrained(model, peft_model_id)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:16:19.094998Z","iopub.execute_input":"2023-12-02T09:16:19.095422Z","iopub.status.idle":"2023-12-02T09:17:41.706429Z","shell.execute_reply.started":"2023-12-02T09:16:19.095394Z","shell.execute_reply":"2023-12-02T09:17:41.705517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display, Markdown\n\ndef make_inference(hedis_measure):\n\n    batch = tokenizer(f\"### Please generate three questions for the customer having the following \\n\\n### Hedis Measure:\\n{hedis_measure}\\n\", return_tensors='pt')\n    batch = batch.to(torch.device('cuda'))\n\n    with torch.cuda.amp.autocast():\n      output_tokens = model.generate(**batch, max_new_tokens=250)\n    # print(tokenizer.decode(output_tokens[0]))\n    display(Markdown((tokenizer.decode(output_tokens[0], skip_special_tokens=True))))","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:47:40.283392Z","iopub.execute_input":"2023-12-02T09:47:40.284156Z","iopub.status.idle":"2023-12-02T09:47:40.290289Z","shell.execute_reply.started":"2023-12-02T09:47:40.284120Z","shell.execute_reply":"2023-12-02T09:47:40.289208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\n# hedis_measure = \"Cardiac Rehabiliation\"\nhedis_measure = \"Lead screening in children\"\nmake_inference(hedis_measure)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:49:37.734261Z","iopub.execute_input":"2023-12-02T09:49:37.734631Z","iopub.status.idle":"2023-12-02T09:49:50.931075Z","shell.execute_reply.started":"2023-12-02T09:49:37.734604Z","shell.execute_reply":"2023-12-02T09:49:50.930140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}